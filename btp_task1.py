# -*- coding: utf-8 -*-
"""BTP_task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eovbcwDe1KAiK1ZQ5NPOC6V1TkriTX3T

discussion from meet:


*   spherical curved object and step function to image under phase shifting
*   normalise them and take some avg no. of photons
*  add poisson noise
*   use TV
*  calculate MSE
* reproduce the graph as in the paper log(A) vs log (n0)
* adding a third axis which is for complexity of object used
"""

import time
from matplotlib import pyplot as plt
import numpy as np
from autograd import grad
from autograd import numpy as anp
from mpl_toolkits.mplot3d import Axes3D
from scipy.ndimage import laplace

def create_complex_object(k, size=256):
    """
    Creates a complex object with a quadratic phase profile and a circular mask.
    The parameter 'k' controls the complexity (curvature) of the phase.
    """
    x = np.linspace(-1, 1, size)
    y = np.linspace(-1, 1, size)
    X, Y = np.meshgrid(x, y)

    phase_map = k * (X**2 + Y**2)
    amplitude = np.ones_like(phase_map)


    radius_sq = X**2 + Y**2
    mask = radius_sq <= 1.0


    # <<< CHANGE: Return the mask along with the other variables.
    return amplitude * np.exp(1j * phase_map), phase_map, X, Y, mask

O_true, phi_o_true, X, Y, mask = create_complex_object(1, size=256)
plt.imshow(phi_o_true, cmap='jet', vmin=-anp.pi, vmax=anp.pi)
plt.title('True Object Phase')
plt.colorbar(label='Phase (rad)')
plt.show()

"""Tv penalty cost optimization method and updating step size t using standard backtracking line search"""

# --- Complexity Calculation ---
def compute_complexity(phi, mask):
    """Calculates complexity based on the mean squared gradient magnitude within a mask."""
    dy, dx = anp.gradient(phi)
    gradient_magnitude_sq = dx**2 + dy**2
    if anp.sum(mask) > 0:
        return anp.sum(gradient_magnitude_sq[mask]) / anp.sum(mask)
    else:
        return 0


def TV_smoothness_penalty(O_complex):
    grad_x, grad_y = anp.gradient(O_complex)
    penalty = anp.sum(anp.abs(grad_x)**2 + anp.abs(grad_y)**2)
    return penalty

gradient_TV=grad(TV_smoothness_penalty)
def tv_phase_retrieval(I_data, R, mask, alpha=1e-3, iterations=50, step_size=1e-3):
     # --- Backtracking Parameters ---
    t = 1.0           # Initial step size to try
    beta_shrink = 0.5 # Factor to shrink t if the step is too large
    c_cond = 0.5      # Condition for sufficient decrease (Armijo condition)
    beta = anp.sqrt(I_data)
    O_estimate = beta*(anp.random.randn(*R.shape) + 1j * anp.random.randn(*R.shape)) * 1e-5

    # --- Nested Cost Function ---
    # This is needed to check if a step size 't' provides sufficient decrease.
    def cost_function(O_est):
        # Data fidelity term
        pred_intensity = anp.abs(O_est + R)**2
        data_cost = anp.sum((I_data - pred_intensity)**2)

        # Regularization term
        reg_cost = TV_smoothness_penalty(O_est)

        return data_cost + alpha * reg_cost

    for i in range(iterations):
        # --- 1. Calculate the gradient at the current position ---
        cost_current = cost_function(O_estimate)

        predicted_intensity = anp.abs(O_estimate + R)**2
        error_term = I_data - predicted_intensity
        beta = anp.sqrt(I_data)
        grad_data = -beta*error_term * (O_estimate + R) # Simplified gradient for data term
        grad_reg = anp.conj(gradient_TV(O_estimate))
        total_gradient = grad_data + alpha * grad_reg
        grad_norm_sq = anp.linalg.norm(total_gradient)**2

        # --- 2. Backtracking Line Search to find the best step size 't' ---
        t = 1e-1 # Reset step size for each iteration
        while cost_function(O_estimate - t * total_gradient) > cost_current - c_cond * t * grad_norm_sq:
            t = beta_shrink * t

        # --- 3. Perform the update with the accepted step size 't' ---
        O_estimate = (O_estimate - t * total_gradient)

    return anp.angle(O_estimate)


def calculate_rmse(phi_true, phi_rec, mask):
    """Calculates Root Mean Squared Error (RMSE)"""
    diff = phi_true - phi_rec
    wrapped_diff = (diff + anp.pi) % (2 * anp.pi) - anp.pi
    mse = anp.sum((wrapped_diff**2))
    return anp.sqrt(mse)

"""New penalty function based on the paper's Eq. 6"""

def neighborhood_penalty(O_complex):
    """
    Calculates the L2-norm smoothness penalty by summing the squared difference
    between each pixel and its four immediate neighbors. This is a direct
    implementation of the paper's Eq. 6 with uniform weights.
    """
    # Create versions of the array shifted right, left, up, and down
    O_right = anp.roll(O_complex, -1, axis=1)
    O_left  = anp.roll(O_complex,  1, axis=1)
    O_down  = anp.roll(O_complex, -1, axis=0)
    O_up    = anp.roll(O_complex,  1, axis=0)

    # Calculate the sum of squared differences between the original and shifted arrays
    diff_sq  = anp.abs(O_complex - O_right)**2
    diff_sq += anp.abs(O_complex - O_left)**2
    diff_sq += anp.abs(O_complex - O_down)**2
    diff_sq += anp.abs(O_complex - O_up)**2

    return anp.sum(diff_sq)

# <<< CHANGE: Get the gradient function for the new neighborhood penalty
gradient_neighborhood = grad(neighborhood_penalty)


# <<< CHANGE: New retrieval function that uses the neighborhood penalty
def l2_retrieval_neighborhood(I_data, R, mask, alpha=1e-5, iterations=50):
    """
    Performs phase retrieval using the neighborhood penalty and backtracking.
    """
    # --- Backtracking Parameters ---
    t = 1.0
    beta_shrink = 0.5
    c_cond = 0.5

    # --- Improved Initial Guess ---
    I_object_avg = np.mean(I_data) - np.mean(np.abs(R)**2)
    amplitude_guess = np.sqrt(max(0, I_object_avg))
    random_phase = anp.random.uniform(-np.pi, np.pi, size=I_data.shape)
    O_estimate = amplitude_guess * anp.exp(1j * random_phase)

    def cost_function(O_est):
        pred_intensity = anp.abs(O_est + R)**2
        data_cost = anp.sum((I_data - pred_intensity)**2)
        # Use the new neighborhood penalty in the cost function
        reg_cost = neighborhood_penalty(O_est)
        return data_cost + alpha * reg_cost

    for i in range(iterations):
        cost_current = cost_function(O_estimate)

        predicted_intensity = anp.abs(O_estimate + R)**2
        error_term = I_data - predicted_intensity
        grad_data = -error_term * (O_estimate + R)

        # <<< CHANGE: Use the gradient from the new neighborhood function
        grad_reg = anp.conj(gradient_neighborhood(O_estimate))

        total_gradient = grad_data + alpha * grad_reg
        grad_norm_sq = anp.linalg.norm(total_gradient)**2

        t = 1.0
        while cost_function(O_estimate - t * total_gradient) > cost_current - c_cond * t * grad_norm_sq:
            t = beta_shrink * t

        O_estimate = (O_estimate - t * total_gradient)

    return anp.angle(O_estimate)

R_beam = 1.0 * anp.exp(1j * (2 * anp.pi * 20 * X+2 * anp.pi * 20 * Y))
phi_r = anp.angle(R_beam)
plt.imshow(phi_r, cmap='jet', vmin=-anp.pi, vmax=anp.pi)
plt.title(f'Reference beam')
plt.colorbar(label='Phase (rad)')
plt.axis('off')
plt.show()

"""# TV based regularization"""

# @title


N0_values = [10, 16, 30, 58, 114, 225, 447, 820]
k_values = [-3.14, -1, 1, 3.14, 6.28, 10]

all_complexity = []
all_log_N0 = []
all_log_G = []

print("Starting simulation for different complexities (k) and photon counts (N0)...")
start_time = time.time()

for i, k in enumerate(k_values):
    print(f"\n===== Running for curvature k = {k:.2f} =====")

    # <<< CHANGE: Unpack the new 'mask' variable from the function.
    O_true, phi_o_true, X, Y, mask = create_complex_object(k, size=256)
    # mask=create_circular_mask(size=256)
    # <<< CHANGE: Pass the mask to the complexity calculation.
    complexity = compute_complexity(phi_o_true, mask)
    print(f"Calculated Phase Complexity: {complexity:.4f}")

    # --- Display True Object Phase ---
    plt.figure(figsize=(5, 4))
    # <<< CHANGE: Multiply by mask to show only the object area.
    plt.imshow(phi_o_true, cmap='jet')
    plt.title(f'initial Object phase (k={k})')
    plt.colorbar(label='Phase (rad)')
    plt.axis('off')
    plt.show()

    phase_shifts = [0, anp.pi/2, anp.pi, 3*anp.pi/2]
    interferograms_HLL = [anp.abs(O_true + R_beam * anp.exp(1j * s))**2 for s in phase_shifts]
    interferograms_HLL=[i/anp.mean(i) for i in interferograms_HLL]
    phi_HLL = anp.arctan2(interferograms_HLL[3] - interferograms_HLL[1], interferograms_HLL[0] - interferograms_HLL[2])
    plt.imshow(phi_HLL, cmap='jet')
    plt.title(f'Ground truth phase (k={k})')
    plt.colorbar(label='Phase (rad)')
    plt.show()
    current_E_ps, current_E_co, current_G = [], [], []

    for j, N0 in enumerate(N0_values):
        # PSM part
        noisy_interferograms_psm = []
        for hll_img in interferograms_HLL:
            scaled_img = hll_img * (N0/4) / anp.mean(hll_img)
            noisy_interferograms_psm.append(anp.random.poisson(scaled_img))

        phi_psm = anp.arctan2(noisy_interferograms_psm[3] - noisy_interferograms_psm[1], noisy_interferograms_psm[0] - noisy_interferograms_psm[2])

        E_ps = calculate_rmse(phi_o_true,phi_r - phi_psm, mask)
        current_E_ps.append(E_ps)

        # CO part
        scaled_img_co = interferograms_HLL[0] * N0 / anp.mean(interferograms_HLL[0])
        noisy_I_co = anp.random.poisson(scaled_img_co)


        phi_co = tv_phase_retrieval(interferograms_HLL[0], R_beam, mask, alpha=50, iterations=20)


        E_co = calculate_rmse(phi_o_true, phi_co, mask)
        current_E_co.append(E_co)

        G = E_ps / E_co if E_co > 0 else 0
        current_G.append(G)

        all_complexity.append(complexity)
        all_log_N0.append(anp.log10(N0))
        all_log_G.append(anp.log10(G) if G > 0 else -np.inf) # Handle log(0)

        # --- Display intermediate plots only for the first N0 value ---
        if j == 1 or j==5:
            fig, axs = plt.subplots(1, 4, figsize=(18, 4))
            # Noisy Interferograms
            im0 = axs[0].imshow(noisy_interferograms_psm[0], cmap='gray')
            axs[0].set_title(f'PSM Noisy Frame (N0={N0})')
            axs[0].axis('off')
            fig.colorbar(im0, ax=axs[0])

            im1 = axs[1].imshow(noisy_I_co, cmap='gray')
            axs[1].set_title(f'CO Noisy Frame (N0={N0})')
            axs[1].axis('off')
            fig.colorbar(im1, ax=axs[1])

            # Retrieved Phases
            im2 = axs[2].imshow(phi_r-phi_psm, cmap='jet',vmin=-np.pi,vmax=np.pi)
            axs[2].set_title(f'PSM Retrieved Phase')
            axs[2].axis('off')
            fig.colorbar(im2, ax=axs[2])

            im3 = axs[3].imshow(phi_co, cmap='jet')
            axs[3].set_title(f'CO Retrieved Phase')
            axs[3].axis('off')
            fig.colorbar(im3, ax=axs[3])

            plt.suptitle(f"Visual Results for k={k}, N0={N0}", fontsize=16)
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            plt.show()

    # --- 2D Plot for the current complexity value ---
    log_N0_vals = anp.log10(N0_values)
    log_E_ps = anp.log10(current_E_ps)
    log_E_co = anp.log10(current_E_co)
    log_G = anp.log10(current_G)

    fit_ps, _ = anp.polyfit(log_N0_vals, log_E_ps, 1)
    fit_co, _ = anp.polyfit(log_N0_vals, log_E_co, 1)
    fit_g, _ = anp.polyfit(log_N0_vals, log_G, 1)

    plt.figure(figsize=(8, 6))
    plt.plot(log_N0_vals, log_G, 'o', color='black', label=f'$log_{{10}}(G)$ [Slope ~ {fit_g:.2f}]')
    plt.plot(log_N0_vals, log_E_ps, 's', color='green', label=f'$log_{{10}}(E_{{ps}})$ [Slope ~ {fit_ps:.2f}]')
    plt.plot(log_N0_vals, log_E_co, '^', color='purple', label=f'$log_{{10}}(E_{{co}})$ [Slope ~ {fit_co:.2f}]')
    # Plot the fitted lines
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_G, 1))(log_N0_vals), '--', color='black')
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_E_ps, 1))(log_N0_vals), '--', color='green')
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_E_co, 1))(log_N0_vals), '--', color='purple')

    plt.xlabel('$log_{10}(N_0)$ - Average Photon Count per Pixel')
    plt.ylabel('$log_{10}(Gain), log_{10}(RMS Error)$')
    plt.title(f"Error & Gain vs. Photon Count for Curvature k={k}")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Print the table of N0 vs G for the current k value
    print(f"\nTable for k = {k:.2f}")
    print("-" * 40)
    print(f"{'N0':<10}{'G':<10}{"E_ps":<10}{"E_co":<10}")
    print("-" * 40)
    for n0, g,E_ps,E_co in zip(N0_values, current_G,current_E_ps,current_E_co):
        print(f"{n0:<10}{g:<10.4f}{E_ps:<10.4f}{E_co:<10.4f}")
    print("-" * 40)


print(f"\nSimulation finished in {time.time() - start_time:.2f} seconds.")

# --- 3D Surface Plot ---
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Convert lists to NumPy arrays for plotting
all_log_N0 = anp.array(all_log_N0)
all_complexity = anp.array(all_complexity)
all_log_G = anp.array(all_log_G)

# Create a surface plot using plot_trisurf
surf = ax.plot_trisurf(all_log_N0, all_complexity, all_log_G, cmap='jet', edgecolor='none')

ax.set_title('Noise Gain vs. Photon Count and Phase Complexity')
ax.set_xlabel('$log_{10}(N_0)$ - Photon Count')
ax.set_ylabel('Phase Complexity')
ax.set_zlabel('$log_{10}(Gain)$')
fig.colorbar(surf, shrink=0.5, aspect=5, label='log10(Gain)')
ax.view_init(elev=20., azim=-120)
plt.show()

"""# nearest neighbors penalty function"""

# @title

N0_values = [10, 16, 30, 58, 114, 225, 447, 820]
k_values = [-3.14, -1, 1, 3.14, 6.28, 10]

all_complexity = []
all_log_N0 = []
all_log_G = []

print("Starting simulation for different complexities (k) and photon counts (N0)...")
start_time = time.time()

for i, k in enumerate(k_values):
    print(f"\n===== Running for curvature k = {k:.2f} =====")

    # <<< CHANGE: Unpack the new 'mask' variable from the function.
    O_true, phi_o_true, X, Y, mask = create_complex_object(k, size=256)

    # <<< CHANGE: Pass the mask to the complexity calculation.
    complexity = compute_complexity(phi_o_true, mask)
    print(f"Calculated Phase Complexity: {complexity:.4f}")

    # --- Display True Object Phase ---
    plt.figure(figsize=(5, 4))
    # <<< CHANGE: Multiply by mask to show only the object area.
    plt.imshow(phi_o_true, cmap='jet',vmin=-np.pi,vmax=np.pi)
    plt.title(f'True Object Phase (k={k})')
    plt.colorbar(label='Phase (rad)')
    plt.axis('off')
    plt.show()

    phase_shifts = [0, anp.pi/2, anp.pi, 3*anp.pi/2]
    interferograms_HLL = [anp.abs(O_true + R_beam * anp.exp(1j * s))**2 for s in phase_shifts]
    phi_HLL = anp.arctan2(interferograms_HLL[3] - interferograms_HLL[1], interferograms_HLL[0] - interferograms_HLL[2])

    current_E_ps, current_E_co, current_G = [], [], []

    for j, N0 in enumerate(N0_values):
        # PSM part
        noisy_interferograms_psm = []
        for hll_img in interferograms_HLL:
            scaled_img = hll_img * (N0/4) / anp.max(hll_img)
            noisy_interferograms_psm.append(anp.random.poisson(scaled_img))

        phi_psm = anp.arctan2(noisy_interferograms_psm[3] - noisy_interferograms_psm[1], noisy_interferograms_psm[0] - noisy_interferograms_psm[2])

        E_ps = calculate_rmse(phi_o_true, phi_psm, mask)
        current_E_ps.append(E_ps)

        # CO part
        scaled_img_co = interferograms_HLL[0] * N0 / anp.max(interferograms_HLL[0])
        noisy_I_co = anp.random.poisson(scaled_img_co)


        phi_co = l2_retrieval_neighborhood(noisy_I_co, R_beam, mask, alpha=1, iterations=25)


        E_co = calculate_rmse(phi_o_true, phi_co , mask)
        current_E_co.append(E_co)

        G = E_ps / E_co if E_co > 0 else 0
        current_G.append(G)

        all_complexity.append(complexity)
        all_log_N0.append(anp.log10(N0))
        all_log_G.append(anp.log10(G) if G > 0 else -np.inf) # Handle log(0)

        # --- Display intermediate plots only for the first N0 value ---
        if j == 1:
            fig, axs = plt.subplots(1, 4, figsize=(18, 4))
            # Noisy Interferograms
            im0 = axs[0].imshow(noisy_interferograms_psm[0], cmap='gray')
            axs[0].set_title(f'PSM Noisy Frame (N0={N0})')
            axs[0].axis('off')
            fig.colorbar(im0, ax=axs[0])

            im1 = axs[1].imshow(noisy_I_co, cmap='gray')
            axs[1].set_title(f'CO Noisy Frame (N0={N0})')
            axs[1].axis('off')
            fig.colorbar(im1, ax=axs[1])

            # Retrieved Phases
            im2 = axs[2].imshow(phi_r-phi_psm , cmap='jet',vmin=-np.pi,vmax=np.pi)
            axs[2].set_title(f'PSM Retrieved Phase')
            axs[2].axis('off')
            fig.colorbar(im2, ax=axs[2])

            im3 = axs[3].imshow(phi_co, cmap='jet')
            axs[3].set_title(f'CO Retrieved Phase')
            axs[3].axis('off')
            fig.colorbar(im3, ax=axs[3])

            plt.suptitle(f"Visual Results for k={k}, N0={N0}", fontsize=16)
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            plt.show()

    # --- 2D Plot for the current complexity value ---
    log_N0_vals = anp.log10(N0_values)
    log_E_ps = anp.log10(current_E_ps)
    log_E_co = anp.log10(current_E_co)
    log_G = anp.log10(current_G)

    fit_ps, _ = anp.polyfit(log_N0_vals, log_E_ps, 1)
    fit_co, _ = anp.polyfit(log_N0_vals, log_E_co, 1)
    fit_g, _ = anp.polyfit(log_N0_vals, log_G, 1)

    plt.figure(figsize=(8, 6))
    plt.plot(log_N0_vals, log_G, 'o', color='black', label=f'$log_{{10}}(G)$ [Slope ~ {fit_g:.2f}]')
    plt.plot(log_N0_vals, log_E_ps, 's', color='green', label=f'$log_{{10}}(E_{{ps}})$ [Slope ~ {fit_ps:.2f}]')
    plt.plot(log_N0_vals, log_E_co, '^', color='purple', label=f'$log_{{10}}(E_{{co}})$ [Slope ~ {fit_co:.2f}]')
    # Plot the fitted lines
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_G, 1))(log_N0_vals), '--', color='black')
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_E_ps, 1))(log_N0_vals), '--', color='green')
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_E_co, 1))(log_N0_vals), '--', color='purple')

    plt.xlabel('$log_{10}(N_0)$ - Average Photon Count per Pixel')
    plt.ylabel('$log_{10}(Gain), log_{10}(RMS Error)$')
    plt.title(f"Error & Gain vs. Photon Count for Curvature k={k}")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Print the table of N0 vs G for the current k value
    print(f"\nTable for k = {k:.2f}")
    print("-" * 40)
    print(f"{'N0':<10}{'G':<10}{"E_ps":<10}{"E_co":<10}")
    print("-" * 40)
    for n0, g,E_ps,E_co in zip(N0_values, current_G,current_E_ps,current_E_co):
        print(f"{n0:<10}{g:<10.4f}{E_ps:<10.4f}{E_co:<10.4f}")
    print("-" * 40)


print(f"\nSimulation finished in {time.time() - start_time:.2f} seconds.")

# --- 3D Surface Plot ---
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Convert lists to NumPy arrays for plotting
all_log_N0 = anp.array(all_log_N0)
all_complexity = anp.array(all_complexity)
all_log_G = anp.array(all_log_G)

# Create a surface plot using plot_trisurf
surf = ax.plot_trisurf(all_log_N0, all_complexity, all_log_G, cmap='jet', edgecolor='none')

ax.set_title('Noise Gain vs. Photon Count and Phase Complexity')
ax.set_xlabel('$log_{10}(N_0)$ - Photon Count')
ax.set_ylabel('Phase Complexity')
ax.set_zlabel('$log_{10}(Gain)$')
fig.colorbar(surf, shrink=0.5, aspect=5, label='log10(Gain)')
ax.view_init(elev=20., azim=-120)
plt.show()

"""# 3x3 neighborhood penalty function"""

def neighborhood_penalty_3x3(O_complex):
    """
    Calculates a more robust L2-norm smoothness penalty by summing the
    squared difference between each pixel and its eight immediate neighbors
    (a 3x3 grid). This version is compatible with autograd.
    """
    # --- 4 Direct Neighbors (Up, Down, Left, Right) ---
    O_right = anp.roll(O_complex, -1, axis=1)
    O_left  = anp.roll(O_complex,  1, axis=1)
    O_down  = anp.roll(O_complex, -1, axis=0)
    O_up    = anp.roll(O_complex,  1, axis=0)

    # --- 4 Diagonal Neighbors (Corrected for autograd) ---
    # By chaining the rolls, we avoid passing a tuple to the 'shift' argument.
    O_down_right = anp.roll(anp.roll(O_complex, -1, axis=0), -1, axis=1) # Shift down, then right
    O_up_left    = anp.roll(anp.roll(O_complex,  1, axis=0),  1, axis=1) # Shift up, then left
    O_down_left  = anp.roll(anp.roll(O_complex, -1, axis=0),  1, axis=1) # Shift down, then left
    O_up_right   = anp.roll(anp.roll(O_complex,  1, axis=0), -1, axis=1) # Shift up, then right

    # Calculate the sum of squared differences for all 8 neighbors
    diff_sq  = anp.abs(O_complex - O_right)**2
    diff_sq += anp.abs(O_complex - O_left)**2
    diff_sq += anp.abs(O_complex - O_down)**2
    diff_sq += anp.abs(O_complex - O_up)**2
    diff_sq += anp.abs(O_complex - O_down_right)**2
    diff_sq += anp.abs(O_complex - O_up_left)**2
    diff_sq += anp.abs(O_complex - O_down_left)**2
    diff_sq += anp.abs(O_complex - O_up_right)**2

    return anp.sum(diff_sq)

gradient_neighborhood_3x3 = grad(neighborhood_penalty_3x3)

def l2_retrieval_3x3(I_data, R, mask, alpha=1e-5, iterations=50):
    """
    Performs phase retrieval using the 3x3 neighborhood penalty and backtracking.
    """
    # --- Backtracking Parameters ---
    t = 1.0
    beta_shrink = 0.5
    c_cond = 0.5

    # --- Improved Initial Guess ---
    I_object_avg = np.mean(I_data) - np.mean(np.abs(R)**2)
    amplitude_guess = np.sqrt(max(0, I_object_avg))
    random_phase = anp.random.uniform(-np.pi, np.pi, size=I_data.shape)
    O_estimate = amplitude_guess * anp.exp(1j * random_phase)

    def cost_function(O_est):
        pred_intensity = anp.abs(O_est + R)**2
        data_cost = anp.sum((I_data - pred_intensity)**2)
        # <<< CHANGE: Use the new 3x3 neighborhood penalty
        reg_cost = neighborhood_penalty_3x3(O_est)
        return data_cost + alpha * reg_cost

    for i in range(iterations):
        cost_current = cost_function(O_estimate)

        predicted_intensity = anp.abs(O_estimate + R)**2
        error_term = I_data - predicted_intensity
        grad_data = -error_term * (O_estimate + R)

        # <<< CHANGE: Use the gradient from the new 3x3 neighborhood function
        grad_reg = anp.conj(gradient_neighborhood_3x3(O_estimate))

        total_gradient = grad_data + alpha * grad_reg
        grad_norm_sq = anp.linalg.norm(total_gradient)**2

        # Backtracking line search
        t = 1.0
        while cost_function(O_estimate - t * total_gradient) > cost_current - c_cond * t * grad_norm_sq:
            t = beta_shrink * t

        # Update estimate
        O_estimate = (O_estimate - t * total_gradient)

    return anp.angle(O_estimate)

# @title

N0_values = [10, 16, 30, 58, 114, 225, 447, 820]
k_values = [-3.14, -1, 1, 3.14, 6.28, 10]

all_complexity = []
all_log_N0 = []
all_log_G = []

print("Starting simulation for different complexities (k) and photon counts (N0)...")
start_time = time.time()

for i, k in enumerate(k_values):
    print(f"\n===== Running for curvature k = {k:.2f} =====")

    # <<< CHANGE: Unpack the new 'mask' variable from the function.
    O_true, phi_o_true, X, Y, mask = create_complex_object(k, size=256)

    # <<< CHANGE: Pass the mask to the complexity calculation.
    complexity = compute_complexity(phi_o_true, mask)
    print(f"Calculated Phase Complexity: {complexity:.4f}")

    # --- Display True Object Phase ---
    plt.figure(figsize=(5, 4))
    # <<< CHANGE: Multiply by mask to show only the object area.
    plt.imshow(phi_o_true, cmap='jet',vmin=-np.pi,vmax=np.pi)
    plt.title(f'True Object Phase (k={k})')
    plt.colorbar(label='Phase (rad)')
    plt.axis('off')
    plt.show()

    phase_shifts = [0, anp.pi/2, anp.pi, 3*anp.pi/2]
    interferograms_HLL = [anp.abs(O_true + R_beam * anp.exp(1j * s))**2 for s in phase_shifts]
    phi_HLL = anp.arctan2(interferograms_HLL[3] - interferograms_HLL[1], interferograms_HLL[0] - interferograms_HLL[2])

    current_E_ps, current_E_co, current_G = [], [], []

    for j, N0 in enumerate(N0_values):
        # PSM part
        noisy_interferograms_psm = []
        for hll_img in interferograms_HLL:
            scaled_img = hll_img * (N0/4) / anp.mean(hll_img)
            noisy_interferograms_psm.append(anp.random.poisson(scaled_img))

        phi_psm = anp.arctan2(noisy_interferograms_psm[3] - noisy_interferograms_psm[1], noisy_interferograms_psm[0] - noisy_interferograms_psm[2])

        E_ps = calculate_rmse(phi_o_true, phi_r-phi_psm, mask)
        current_E_ps.append(E_ps)

        # CO part
        scaled_img_co = interferograms_HLL[0] * N0 / anp.mean(interferograms_HLL[0])
        noisy_I_co = anp.random.poisson(scaled_img_co)


        phi_co = l2_retrieval_3x3(interferograms_HLL[0], R_beam, mask, alpha=5, iterations=25)


        E_co = calculate_rmse(phi_o_true, phi_co , mask)
        current_E_co.append(E_co)

        G = E_ps / E_co if E_co > 0 else 0
        current_G.append(G)

        all_complexity.append(complexity)
        all_log_N0.append(anp.log10(N0))
        all_log_G.append(anp.log10(G) if G > 0 else -np.inf) # Handle log(0)

        # --- Display intermediate plots only for the first N0 value ---
        if j == 1 :
            fig, axs = plt.subplots(1, 4, figsize=(18, 4))
            # Noisy Interferograms
            im0 = axs[0].imshow(noisy_interferograms_psm[0], cmap='gray')
            axs[0].set_title(f'PSM Noisy Frame (N0={N0})')
            axs[0].axis('off')
            fig.colorbar(im0, ax=axs[0])

            im1 = axs[1].imshow(noisy_I_co, cmap='gray')
            axs[1].set_title(f'CO Noisy Frame (N0={N0})')
            axs[1].axis('off')
            fig.colorbar(im1, ax=axs[1])

            # Retrieved Phases
            im2 = axs[2].imshow(phi_r-phi_psm , cmap='jet',vmin=-np.pi,vmax=np.pi)
            axs[2].set_title(f'PSM Retrieved Phase')
            axs[2].axis('off')
            fig.colorbar(im2, ax=axs[2])

            im3 = axs[3].imshow(phi_co, cmap='jet')
            axs[3].set_title(f'CO Retrieved Phase')
            axs[3].axis('off')
            fig.colorbar(im3, ax=axs[3])

            plt.suptitle(f"Visual Results for k={k}, N0={N0}", fontsize=16)
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            plt.show()

    # --- 2D Plot for the current complexity value ---
    log_N0_vals = anp.log10(N0_values)
    log_E_ps = anp.log10(current_E_ps)
    log_E_co = anp.log10(current_E_co)
    log_G = anp.log10(current_G)

    fit_ps, _ = anp.polyfit(log_N0_vals, log_E_ps, 1)
    fit_co, _ = anp.polyfit(log_N0_vals, log_E_co, 1)
    fit_g, _ = anp.polyfit(log_N0_vals, log_G, 1)

    plt.figure(figsize=(8, 6))
    plt.plot(log_N0_vals, log_G, 'o', color='black', label=f'$log_{{10}}(G)$ [Slope ~ {fit_g:.2f}]')
    plt.plot(log_N0_vals, log_E_ps, 's', color='green', label=f'$log_{{10}}(E_{{ps}})$ [Slope ~ {fit_ps:.2f}]')
    plt.plot(log_N0_vals, log_E_co, '^', color='purple', label=f'$log_{{10}}(E_{{co}})$ [Slope ~ {fit_co:.2f}]')
    # Plot the fitted lines
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_G, 1))(log_N0_vals), '--', color='black')
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_E_ps, 1))(log_N0_vals), '--', color='green')
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_E_co, 1))(log_N0_vals), '--', color='purple')

    plt.xlabel('$log_{10}(N_0)$ - Average Photon Count per Pixel')
    plt.ylabel('$log_{10}(Gain), log_{10}(RMS Error)$')
    plt.title(f"Error & Gain vs. Photon Count for Curvature k={k}")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Print the table of N0 vs G for the current k value
    print(f"\nTable for k = {k:.2f}")
    print("-" * 40)
    print(f"{'N0':<10}{'G':<10}{"E_ps":<10}{"E_co":<10}")
    print("-" * 40)
    for n0, g,E_ps,E_co in zip(N0_values, current_G,current_E_ps,current_E_co):
        print(f"{n0:<10}{g:<10.4f}{E_ps:<10.4f}{E_co:<10.4f}")
    print("-" * 40)


print(f"\nSimulation finished in {time.time() - start_time:.2f} seconds.")

# --- 3D Surface Plot ---
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Convert lists to NumPy arrays for plotting
all_log_N0 = anp.array(all_log_N0)
all_complexity = anp.array(all_complexity)
all_log_G = anp.array(all_log_G)

# Create a surface plot using plot_trisurf
surf = ax.plot_trisurf(all_log_N0, all_complexity, all_log_G, cmap='jet', edgecolor='none')

ax.set_title('Noise Gain vs. Photon Count and Phase Complexity')
ax.set_xlabel('$log_{10}(N_0)$ - Photon Count')
ax.set_ylabel('Phase Complexity')
ax.set_zlabel('$log_{10}(Gain)$')
fig.colorbar(surf, shrink=0.5, aspect=5, label='log10(Gain)')
ax.view_init(elev=20., azim=-120)
plt.show()

"""# using laplace"""

# @title
def constrained_optimization_method(I_noisy, R, alpha, iterations=20, step_size=1e-5, plot_every=5):
    O_n = np.ones_like(I_noisy,dtype=np.complex128)
    for i in range(iterations):
        I_model = np.abs(O_n + R)**2
        beta = np.sqrt(I_noisy + 1)
        grad_data = -beta * (I_noisy - I_model) * (O_n + R)
        grad_regularizer = -laplace(O_n, mode='reflect')
        total_gradient = grad_data + alpha * grad_regularizer
        O_n = O_n - step_size * total_gradient


        if np.any(np.isnan(O_n)) or np.any(np.isinf(O_n)):
            print(f"Numerical instability at iteration {i}")
            break
    # plt.figure(figsize=(6, 5))
    # plt.imshow(np.angle(O_n), cmap='jet')
    # plt.title(f'CO Phase')
    # plt.colorbar()
    # plt.show()
    return np.angle(O_n)

# @title

N0_values = [10, 16, 30, 58, 114, 225, 447, 820]
k_values = [-3.14, -1, 1, 3.14, 6.28, 10]

all_complexity = []
all_log_N0 = []
all_log_G = []

print("Starting simulation for different complexities (k) and photon counts (N0)...")
start_time = time.time()

for i, k in enumerate(k_values):
    print(f"\n===== Running for curvature k = {k:.2f} =====")

    # <<< CHANGE: Unpack the new 'mask' variable from the function.
    O_true, phi_o_true, X, Y, mask = create_complex_object(k, size=256)

    # <<< CHANGE: Pass the mask to the complexity calculation.
    complexity = compute_complexity(phi_o_true, mask)
    print(f"Calculated Phase Complexity: {complexity:.4f}")

    # --- Display True Object Phase ---
    plt.figure(figsize=(5, 4))
    # <<< CHANGE: Multiply by mask to show only the object area.
    plt.imshow(phi_o_true, cmap='jet', vmin=-anp.pi, vmax=anp.pi)
    plt.title(f'True Object Phase (k={k})')
    plt.colorbar(label='Phase (rad)')
    plt.axis('off')
    plt.show()

    phase_shifts = [0, anp.pi/2, anp.pi, 3*anp.pi/2]
    interferograms_HLL = [anp.abs(O_true + R_beam * anp.exp(1j * s))**2 for s in phase_shifts]
    phi_HLL = anp.arctan2(interferograms_HLL[3] - interferograms_HLL[1], interferograms_HLL[0] - interferograms_HLL[2])
    # plt.imshow(phi_HLL, cmap='jet')
    # plt.title(f'Ground truth phase (k={k})')
    # plt.colorbar(label='Phase (rad)')
    # plt.show()
    current_E_ps, current_E_co, current_G = [], [], []

    for j, N0 in enumerate(N0_values):
        # PSM part
        noisy_interferograms_psm = []
        for hll_img in interferograms_HLL:
            scaled_img = hll_img * (N0/4) / anp.max(hll_img)
            noisy_interferograms_psm.append(anp.random.poisson(scaled_img))

        phi_psm = anp.arctan2(noisy_interferograms_psm[3] - noisy_interferograms_psm[1], noisy_interferograms_psm[0] - noisy_interferograms_psm[2])

        E_ps = calculate_rmse(phi_HLL, phi_psm, mask)
        current_E_ps.append(E_ps)

        # CO part
        scaled_img_co = interferograms_HLL[0] * N0 / anp.max(interferograms_HLL[0])
        noisy_I_co = anp.random.poisson(scaled_img_co)


        phi_co = constrained_optimization_method(noisy_I_co, R_beam,10)


        E_co = calculate_rmse(phi_HLL, phi_co - phi_r, mask)
        current_E_co.append(E_co)

        G = E_ps / E_co if E_co > 0 else 0
        current_G.append(G)

        all_complexity.append(complexity)
        all_log_N0.append(anp.log10(N0))
        all_log_G.append(anp.log10(G) if G > 0 else -np.inf) # Handle log(0)

        # --- Display intermediate plots only for the first N0 value ---
        if j == 1:
            fig, axs = plt.subplots(1, 4, figsize=(18, 4))
            # Noisy Interferograms
            im0 = axs[0].imshow(noisy_interferograms_psm[0], cmap='gray')
            axs[0].set_title(f'PSM Noisy Frame (N0={N0})')
            axs[0].axis('off')
            fig.colorbar(im0, ax=axs[0])

            im1 = axs[1].imshow(noisy_I_co, cmap='gray')
            axs[1].set_title(f'CO Noisy Frame (N0={N0})')
            axs[1].axis('off')
            fig.colorbar(im1, ax=axs[1])

            # Retrieved Phases
            im2 = axs[2].imshow(phi_psm+phi_r , cmap='jet', vmin=-anp.pi, vmax=anp.pi)
            axs[2].set_title(f'PSM Retrieved Phase')
            axs[2].axis('off')
            fig.colorbar(im2, ax=axs[2])

            im3 = axs[3].imshow(phi_co, cmap='jet', vmin=-anp.pi, vmax=anp.pi)
            axs[3].set_title(f'CO Retrieved Phase')
            axs[3].axis('off')
            fig.colorbar(im3, ax=axs[3])

            plt.suptitle(f"Visual Results for k={k}, N0={N0}", fontsize=16)
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            plt.show()

    # --- 2D Plot for the current complexity value ---
    log_N0_vals = anp.log10(N0_values)
    log_E_ps = anp.log10(current_E_ps)
    log_E_co = anp.log10(current_E_co)
    log_G = anp.log10(current_G)

    fit_ps, _ = anp.polyfit(log_N0_vals, log_E_ps, 1)
    fit_co, _ = anp.polyfit(log_N0_vals, log_E_co, 1)
    fit_g, _ = anp.polyfit(log_N0_vals, log_G, 1)

    plt.figure(figsize=(8, 6))
    plt.plot(log_N0_vals, log_G, 'o', color='black', label=f'$log_{{10}}(G)$ [Slope ~ {fit_g:.2f}]')
    plt.plot(log_N0_vals, log_E_ps, 's', color='green', label=f'$log_{{10}}(E_{{ps}})$ [Slope ~ {fit_ps:.2f}]')
    plt.plot(log_N0_vals, log_E_co, '^', color='purple', label=f'$log_{{10}}(E_{{co}})$ [Slope ~ {fit_co:.2f}]')
    # Plot the fitted lines
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_G, 1))(log_N0_vals), '--', color='black')
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_E_ps, 1))(log_N0_vals), '--', color='green')
    plt.plot(log_N0_vals, anp.poly1d(anp.polyfit(log_N0_vals, log_E_co, 1))(log_N0_vals), '--', color='purple')

    plt.xlabel('$log_{10}(N_0)$ - Average Photon Count per Pixel')
    plt.ylabel('$log_{10}(Gain), log_{10}(RMS Error)$')
    plt.title(f"Error & Gain vs. Photon Count for Curvature k={k}")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Print the table of N0 vs G for the current k value
    print(f"\nTable for k = {k:.2f}")
    print("-" * 40)
    print(f"{'N0':<10}{'G':<10}{"E_ps":<10}{"E_co":<10}")
    print("-" * 40)
    for n0, g,E_ps,E_co in zip(N0_values, current_G,current_E_ps,current_E_co):
        print(f"{n0:<10}{g:<10.4f}{E_ps:<10.4f}{E_co:<10.4f}")
    print("-" * 40)


print(f"\nSimulation finished in {time.time() - start_time:.2f} seconds.")

# --- 3D Surface Plot ---
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Convert lists to NumPy arrays for plotting
all_log_N0 = anp.array(all_log_N0)
all_complexity = anp.array(all_complexity)
all_log_G = anp.array(all_log_G)

# Create a surface plot using plot_trisurf
surf = ax.plot_trisurf(all_log_N0, all_complexity, all_log_G, cmap='jet', edgecolor='none')

ax.set_title('Noise Gain vs. Photon Count and Phase Complexity')
ax.set_xlabel('$log_{10}(N_0)$ - Photon Count')
ax.set_ylabel('Phase Complexity')
ax.set_zlabel('$log_{10}(Gain)$')
fig.colorbar(surf, shrink=0.5, aspect=5, label='log10(Gain)')
ax.view_init(elev=20., azim=-120)
plt.show()

"""# Phase-only optimization on Step function"""

# we have already defined TV2 function above and now it needs to be applied only on theta
# cost function : C(theta)=|| H - (R^2 + O^2 + 2|R||O|cos(theta-theta_r))||^2 + alpha . TV(theta)

def TV_smoothness_penalty(phase):
    grad_x, grad_y = anp.gradient(phase)
    penalty = anp.sum(anp.abs(grad_x)**2 + anp.abs(grad_y)**2)
    return penalty

gradient_TV=grad(TV_smoothness_penalty)
def tv_phase_retrieval(H,O, R, mask, alpha=1e-3, iterations=50, step_size=1e-3):
     # --- Backtracking Parameters ---
    t = 1.0           # Initial step size to try
    beta_shrink = 0.5 # Factor to shrink t if the step is too large
    c_cond = 0.5      # Condition for sufficient decrease (Armijo condition)

    phi_estimate = (anp.random.randn(*R.shape) + 1j * anp.random.randn(*R.shape)) * 1e-5

    # --- Nested Cost Function ---
    # This is needed to check if a step size 't' provides sufficient decrease.
    def cost_function(phi_est):
        # Data fidelity term
        pred_intensity = anp.abs(R)**2 + anp.abs(O)**2 + 2 * anp.abs(R) * anp.abs(O) * anp.cos(phi_est - phi_r)
        data_cost = anp.sum((H - pred_intensity)**2)

        # Regularization term
        reg_cost = TV_smoothness_penalty(phi_est)

        return data_cost + alpha * reg_cost

    for i in range(iterations):
        # --- 1. Calculate the gradient at the current position ---
        cost_current = cost_function(phi_estimate)

        pred_intensity = anp.abs(R)**2 + anp.abs(O)**2 + 2 * anp.abs(R) * anp.abs(O) * anp.cos(phi_estimate - phi_r)
        error_term = H - pred_intensity
        grad_data = 2* anp.abs(R) * anp.abs(O)*error_term * anp.sin(phi_estimate - phi_r) # Simplified gradient for data term
        grad_reg = (gradient_TV(phi_estimate))
        total_gradient = grad_data + alpha * grad_reg
        grad_norm_sq = anp.linalg.norm(total_gradient)**2

        # --- 2. Backtracking Line Search to find the best step size 't' ---
        t = 1e-1 # Reset step size for each iteration
        while cost_function(phi_estimate - t * total_gradient) > cost_current - c_cond * t * grad_norm_sq:
            t = beta_shrink * t

        # --- 3. Perform the update with the accepted step size 't' ---
        phi_estimate = (phi_estimate - t * total_gradient)

    return phi_estimate

def generate_rectangle(size, width=0.6, height=0.4, phase=1):
    x = np.linspace(-1, 1, size)
    y = np.linspace(-1, 1, size)
    xx, yy = np.meshgrid(x, y)

    mask = (np.abs(xx) < width/2) & (np.abs(yy) < height/2)
    obj_amp = 1
    obj_phase = phase * mask

    o_true = obj_amp * np.exp(1j * obj_phase)

    tilt_x = 20 * np.pi
    r_beam = np.exp(1j * tilt_x * xx)

    return o_true,obj_phase,mask
o,obj_phase,mask=generate_rectangle(256)
plt.imshow(np.angle(o),cmap='grey')
plt.title(f'Object Phase')
plt.colorbar(label='Phase (rad)')
plt.show()

# applying the phase-only optimisation to the rectangular object
H = np.abs(o + R_beam)**2
phi_estimated=tv_phase_retrieval(H,o, R_beam, mask, alpha=1, iterations=100, step_size=1e-3)


plt.imshow(np.abs(phi_estimated), cmap='grey')
plt.title(f'Estimated Phase')
plt.colorbar(label='Phase (rad)')
plt.show()

H1 = np.abs(1*np.exp(1j * phi_estimated) + R_beam)**2
H = np.abs(o + R_beam)**2
# phi_estimated2=tv_phase_retrieval(H,1*np.exp(1j * phi_estimated), R_beam, mask, alpha=1e-3, iterations=100, step_size=1e-3)

plt.imshow(np.abs(H), cmap='grey')
plt.title(f'Estimated Phase')
plt.colorbar(label='Phase (rad)')
plt.show()

plt.imshow(np.abs(H1), cmap='grey')
plt.title(f'Estimated Phase')
plt.colorbar(label='Phase (rad)')
plt.show()

print(TV_smoothness_penalty(o))
print(TV_smoothness_penalty(1*np.exp(1j * phi_estimated) ))

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import autograd.numpy as anp
from autograd import grad

def load_phase_image(image_path):
    """Load phase image and normalize to [0, 2π]"""
    img = Image.open(image_path).convert('L')  # Convert to grayscale
    phase_img = np.array(img, dtype=float)

    # Normalize to [0, 2π]
    phase_img_normalized = (phase_img - phase_img.min()) / (phase_img.max() - phase_img.min()) * 2 * np.pi

    return phase_img_normalized

def create_reference_field_from_peak(phase_image, energy_fraction=0.5, peak_radius=1):
    """Create reference field by extracting peak from FT of input image"""

    # Take Fourier transform of the phase image
    ft_image = np.fft.fft2(phase_image)
    ft_magnitude = np.abs(ft_image)

    # Find the peak location (excluding DC component at center)
    h, w = phase_image.shape
    center_h, center_w = h//2, w//2

    # Create a mask to exclude the DC component
    mask = np.ones((h, w))
    # Exclude center region (DC component and low frequencies)
    mask[center_h-10:center_h+11, center_w-10:center_w+11] = 0

    # Find peak in the masked FT
    ft_masked = ft_magnitude * mask
    peak_idx = np.unravel_index(np.argmax(ft_masked), ft_masked.shape)

    print(f"Peak found at frequency: {peak_idx}")
    print(f"Peak magnitude: {ft_magnitude[peak_idx]}")

    # Create reference field in Fourier domain
    ft_ref = np.zeros((h, w), dtype=complex)

    # Set a small region around the peak to 1
    for i in range(-peak_radius, peak_radius+1):
        for j in range(-peak_radius, peak_radius+1):
            idx_h = (peak_idx[0] + i) % h
            idx_w = (peak_idx[1] + j) % w
            ft_ref[idx_h, idx_w] = 1.0

    # Inverse Fourier transform to get spatial reference field
    R_spatial = np.fft.ifft2(ft_ref)

    # Scale to have the desired energy fraction
    current_energy = np.sum(np.abs(R_spatial)**2)
    scale_factor = np.sqrt(energy_fraction / current_energy)
    R = scale_factor * R_spatial

    return R, peak_idx, ft_magnitude

def create_object_field(phase_image, energy_fraction=0.5):
    """Create object field with specified energy fraction from phase image"""
    amplitude = np.sqrt(energy_fraction)
    O = amplitude * np.exp(1j * phase_image)
    return O

def TV_smoothness_penalty(phase):
    """Total Variation smoothness penalty"""
    grad_x, grad_y = anp.gradient(phase)
    penalty = anp.sum(anp.abs(grad_x)**2 + anp.abs(grad_y)**2)
    return penalty

# Gradient of TV penalty
gradient_TV = grad(TV_smoothness_penalty)

def tv_phase_retrieval(H, O_abs, R, alpha=1e-3, iterations=100):
    """Phase retrieval with TV regularization"""
    # Extract amplitudes and phases
    R_abs = anp.abs(R)
    phi_r = anp.angle(R)

    # Backtracking Parameters
    t = 1.0
    beta_shrink = 0.5
    c_cond = 0.5

    # Initialize phase estimate
    phi_estimate = anp.random.randn(*R.shape) * 1e-5

    # Nested Cost Function
    def cost_function(phi_est):
        # Data fidelity term
        pred_intensity = R_abs**2 + O_abs**2 + 2 * R_abs * O_abs * anp.cos(phi_est - phi_r)
        data_cost = anp.sum((H - pred_intensity)**2)

        # Regularization term
        reg_cost = TV_smoothness_penalty(phi_est)

        return data_cost + alpha * reg_cost

    cost_history = []

    for i in range(iterations):
        # Calculate the gradient at the current position
        cost_current = cost_function(phi_estimate)

        pred_intensity = R_abs**2 + O_abs**2 + 2 * R_abs * O_abs * anp.cos(phi_estimate - phi_r)
        error_term = H - pred_intensity
        grad_data = 2 * R_abs * O_abs * error_term * anp.sin(phi_estimate - phi_r)
        grad_reg = gradient_TV(phi_estimate)
        total_gradient = grad_data + alpha * grad_reg
        grad_norm_sq = anp.linalg.norm(total_gradient)**2

        # Backtracking Line Search
        t = 1e-1  # Reset step size for each iteration
        while cost_function(phi_estimate - t * total_gradient) > cost_current - c_cond * t * grad_norm_sq:
            t = beta_shrink * t

        # Perform the update with the accepted step size
        phi_estimate = phi_estimate - t * total_gradient

        cost_history.append(cost_current)

        if i % 20 == 0:
            print(f"Iteration {i}, Cost: {cost_current:.6f}")

    return phi_estimate, cost_history

def reconstruct_single_hologram(image_path, alpha=1e-3, iterations=100):
    """Reconstruct phase from a single hologram image using peak-based reference"""

    # Load phase image
    phase_img = load_phase_image(image_path)

    # Create object field (half energy)
    O = create_object_field(phase_img, energy_fraction=0.5)
    O_abs = anp.abs(O)  # We know the amplitude but not the phase

    # Create reference field from FT peak (half energy)
    R, peak_idx, ft_magnitude = create_reference_field_from_peak(phase_img, energy_fraction=0.5)

    # Create synthetic hologram (in real scenario, this is your measured hologram)
    H = anp.abs(R + O)**2

    print(f"Reconstructing {image_path}...")
    print(f"Image shape: {phase_img.shape}")
    print(f"Reference peak frequency: {peak_idx}")

    # Apply phase retrieval
    phi_reconstructed, cost_history = tv_phase_retrieval(
        H, O_abs, R, alpha=alpha, iterations=iterations
    )

    # Reconstruct the final object field
    O_reconstructed = O_abs * anp.exp(1j * phi_reconstructed)

    return O_reconstructed, phi_reconstructed, cost_history, H, ft_magnitude, peak_idx

def compare_reconstructions(image_path1, image_path2):
    """Compare reconstructions of two independent hologram images"""

    # Reconstruct first image
    O_recon1, phi_recon1, cost_hist1, H1, ft_mag1, peak1 = reconstruct_single_hologram(
        image_path1, alpha=1e-3, iterations=100
    )

    # Reconstruct second image
    O_recon2, phi_recon2, cost_hist2, H2, ft_mag2, peak2 = reconstruct_single_hologram(
        image_path2, alpha=1e-3, iterations=100
    )

    # Plot results
    fig, axes = plt.subplots(2, 5, figsize=(25, 10))

    # Image 1 results
    axes[0, 0].imshow(H1, cmap='gray')
    axes[0, 0].set_title('Hologram 1')
    axes[0, 0].axis('off')

    axes[0, 1].imshow(np.log(1 + ft_mag1), cmap='hot')
    axes[0, 1].plot(peak1[1], peak1[0], 'bx', markersize=10, markeredgewidth=2)
    axes[0, 1].set_title(f'FT Magnitude 1\nPeak at {peak1}')
    axes[0, 1].axis('off')

    axes[0, 2].imshow(anp.angle(O_recon1), cmap='hsv')
    axes[0, 2].set_title('Reconstructed Phase 1')
    axes[0, 2].axis('off')

    axes[0, 3].imshow(anp.abs(O_recon1), cmap='gray')
    axes[0, 3].set_title('Reconstructed Amplitude 1')
    axes[0, 3].axis('off')

    axes[0, 4].plot(cost_hist1)
    axes[0, 4].set_title('Cost History 1')
    axes[0, 4].set_yscale('log')

    # Image 2 results
    axes[1, 0].imshow(H2, cmap='gray')
    axes[1, 0].set_title('Hologram 2')
    axes[1, 0].axis('off')

    axes[1, 1].imshow(np.log(1 + ft_mag2), cmap='hot')
    axes[1, 1].plot(peak2[1], peak2[0], 'bx', markersize=10, markeredgewidth=2)
    axes[1, 1].set_title(f'FT Magnitude 2\nPeak at {peak2}')
    axes[1, 1].axis('off')

    axes[1, 2].imshow(anp.angle(O_recon2), cmap='hsv')
    axes[1, 2].set_title('Reconstructed Phase 2')
    axes[1, 2].axis('off')

    axes[1, 3].imshow(anp.abs(O_recon2), cmap='gray')
    axes[1, 3].set_title('Reconstructed Amplitude 2')
    axes[1, 3].axis('off')

    axes[1, 4].plot(cost_hist2)
    axes[1, 4].set_title('Cost History 2')
    axes[1, 4].set_yscale('log')

    plt.tight_layout()
    plt.show()

    return (O_recon1, phi_recon1, cost_hist1), (O_recon2, phi_recon2, cost_hist2)

# Example usage
if __name__ == "__main__":
    # Replace with your actual image paths
    image1_path = "/content/1dhm.png"
    image2_path = "/content/37a.png"

    try:
        results1, results2 = compare_reconstructions(image1_path, image2_path)

        print("Reconstruction completed successfully!")
        print(f"Final cost image 1: {results1[2][-1]:.6f}")
        print(f"Final cost image 2: {results2[2][-1]:.6f}")

    except FileNotFoundError as e:
        print(f"File not found: {e}")
        print("Creating sample images for demonstration...")

        # Create sample phase images with specific frequency content
        h, w = 256, 256
        x, y = np.meshgrid(np.linspace(-np.pi, np.pi, w), np.linspace(-np.pi, np.pi, h))

        # First sample: pattern with strong frequency components
        phase1 = np.sin(3*x) * np.cos(2*y) + 0.5*np.sin(8*x + 4*y)
        img1 = Image.fromarray(((phase1 - phase1.min()) * 255 / (phase1.max() - phase1.min())).astype(np.uint8))
        img1.save('sample_hologram1.png')

        # Second sample: different frequency pattern
        phase2 = np.cos(5*x) * np.sin(7*y) + 0.3*np.cos(12*x - 3*y)
        img2 = Image.fromarray(((phase2 - phase2.min()) * 255 / (phase2.max() - phase2.min())).astype(np.uint8))
        img2.save('sample_hologram2.png')

        print("Created sample images with specific frequency content")
        print("Run the script again to process these sample images")

